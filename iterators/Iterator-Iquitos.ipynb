{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # for visualiation\n",
    "import statsmodels.formula.api as smf # linear modeling\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Load data\n",
    "data_features = pd.read_csv('./data/dengue_features_train.csv')\n",
    "data_labels = pd.read_csv('./data/dengue_labels_train.csv')\n",
    "data_test = pd.read_csv('./data/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Weeks', 'Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "50\n",
      "8.69891879839679\n",
      "done\n",
      "51\n",
      "8.390135280315942\n",
      "done\n",
      "52\n",
      "8.459309671091683\n",
      "done\n",
      "53\n",
      "8.53747294307873\n",
      "done\n",
      "54\n",
      "8.270487230797796\n",
      "done\n",
      "55\n",
      "9.888118743512683\n",
      "done\n",
      "56\n",
      "9.394894764547217\n",
      "done\n",
      "57\n",
      "8.472587219221111\n",
      "done\n",
      "58\n",
      "8.44378285541248\n",
      "done\n",
      "59\n",
      "9.274486468596193\n",
      "done\n",
      "60\n",
      "8.79386520049468\n",
      "done\n",
      "61\n",
      "9.076113346557108\n",
      "done\n",
      "62\n",
      "8.169555499685845\n",
      "done\n",
      "63\n",
      "9.95443378545255\n",
      "done\n",
      "64\n",
      "8.696496581574232\n",
      "done\n",
      "65\n",
      "8.151893151203295\n",
      "done\n",
      "66\n",
      "9.353318355670188\n",
      "done\n",
      "67\n",
      "10.669718522232113\n",
      "done\n",
      "68\n",
      "9.91190450069965\n",
      "done\n",
      "69\n",
      "8.841986275641945\n",
      "done\n",
      "70\n",
      "9.02533105811282\n",
      "done\n",
      "71\n",
      "11.971891534720084\n",
      "done\n",
      "72\n",
      "8.135757829321673\n",
      "done\n",
      "73\n",
      "8.605491470420336\n",
      "done\n",
      "74\n",
      "8.176972226111873\n",
      "done\n",
      "75\n",
      "10.21217123238709\n",
      "done\n",
      "76\n",
      "8.261927394911398\n",
      "done\n",
      "77\n",
      "8.739052074486047\n",
      "done\n",
      "78\n",
      "9.41188427912122\n",
      "done\n",
      "79\n",
      "11.485764020967617\n",
      "done\n",
      "80\n",
      "7.556257309080113\n",
      "done\n",
      "81\n",
      "9.822179464023295\n",
      "done\n",
      "82\n",
      "9.221126574735807\n",
      "done\n",
      "83\n",
      "7.139809092139034\n",
      "done\n",
      "84\n",
      "9.275780497603098\n",
      "done\n",
      "85\n",
      "8.51980187003053\n",
      "done\n",
      "86\n",
      "7.721438410138937\n",
      "done\n",
      "87\n",
      "9.437124469679052\n",
      "done\n",
      "88\n",
      "7.58793745765031\n",
      "done\n",
      "89\n",
      "10.833499053115737\n",
      "done\n",
      "90\n",
      "8.019299853469386\n",
      "done\n",
      "91\n",
      "8.663755046919716\n",
      "done\n",
      "92\n",
      "9.334047434140317\n",
      "done\n",
      "93\n",
      "9.034072841134584\n",
      "done\n",
      "94\n",
      "8.884719401185865\n",
      "done\n",
      "95\n",
      "7.265947948401877\n",
      "done\n",
      "96\n",
      "9.440301364270772\n",
      "done\n",
      "97\n",
      "8.917731839012813\n",
      "done\n",
      "98\n",
      "8.9519563815308\n",
      "done\n",
      "99\n",
      "10.275312983905472\n",
      "done\n",
      "100\n",
      "9.07880982236162\n",
      "done\n",
      "101\n",
      "6.482190226389246\n",
      "done\n",
      "102\n",
      "7.916419016853174\n",
      "done\n",
      "103\n",
      "9.970889884880172\n",
      "done\n",
      "104\n",
      "7.895198432515727\n",
      "done\n",
      "105\n",
      "7.751401131953318\n",
      "done\n",
      "106\n",
      "7.3639655357830165\n"
     ]
    }
   ],
   "source": [
    "for n in range(50, 107):\n",
    "    \n",
    "    ###################################################\n",
    "    # Data Prep\n",
    "    ###################################################\n",
    "    \n",
    "    #Features\n",
    "    data_features_iq = data_features[data_features.city=='sj'].reset_index(drop = True)\n",
    "    data_labels_iq = data_labels[data_labels.city=='sj'].reset_index(drop = True)\n",
    "    data_iq = pd.merge(data_features_iq, data_labels_iq)\n",
    "    data_iq = data_iq.drop(columns=['reanalysis_sat_precip_amt_mm', 'reanalysis_specific_humidity_g_per_kg'])\n",
    "\n",
    "    data_iq = data_iq.fillna(method = 'ffill')\n",
    "    data_iq['month'] = pd.to_datetime(data_iq['week_start_date']).dt.month\n",
    "    data_iq['odd_year'] = data_iq.year.astype('int64') % 2 == 1\n",
    "    data_iq['ndvi_mean'] = (data_iq['ndvi_ne'] + data_iq['ndvi_nw'] + data_iq['ndvi_se'] + data_iq['ndvi_sw']) / 4.0\n",
    "\n",
    "    # data_iq = data_iq[data_iq['year'].isin(['1990','1991','1992','1993','1995','1996','1997','1999','2000','2001','2002','2003','2004','2005','2006','2007','2008'])]\n",
    "\n",
    "    data_iq['ndvi_mean_rolling_avg'] = data_iq['ndvi_mean'].rolling(window = n).mean()\n",
    "    data_iq['ndvi_ne_rolling_avg'] = data_iq['ndvi_ne'].rolling(window = n).mean()\n",
    "    data_iq['ndvi_nw_rolling_avg'] = data_iq['ndvi_nw'].rolling(window = n).mean()\n",
    "    data_iq['ndvi_se_rolling_avg'] = data_iq['ndvi_se'].rolling(window = n).mean()\n",
    "    data_iq['ndvi_sw_rolling_avg'] = data_iq['ndvi_sw'].rolling(window = n).mean()\n",
    "    data_iq['precipitation_amt_mm_rolling_avg'] = data_iq['precipitation_amt_mm'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_air_temp_k_rolling_avg'] = data_iq['reanalysis_air_temp_k'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_avg_temp_k_rolling_avg'] = data_iq['reanalysis_avg_temp_k'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_dew_point_temp_k_rolling_avg'] = data_iq['reanalysis_dew_point_temp_k'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_max_air_temp_k_rolling_avg'] = data_iq['reanalysis_max_air_temp_k'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_min_air_temp_k_rolling_avg'] = data_iq['reanalysis_min_air_temp_k'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_precip_amt_kg_per_m2_rolling_avg'] = data_iq['reanalysis_precip_amt_kg_per_m2'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_relative_humidity_percent_rolling_avg'] = data_iq['reanalysis_relative_humidity_percent'].rolling(window = n).mean()\n",
    "    data_iq['reanalysis_tdtr_k_rolling_avg'] = data_iq['reanalysis_tdtr_k'].rolling(window = n).mean()\n",
    "    data_iq['station_avg_temp_c_rolling_avg'] = data_iq['station_avg_temp_c'].rolling(window = n).mean()\n",
    "    data_iq['station_diur_temp_rng_c_rolling_avg'] = data_iq['station_diur_temp_rng_c'].rolling(window = n).mean()\n",
    "    data_iq['station_max_temp_c_rolling_avg'] = data_iq['station_max_temp_c'].rolling(window = n).mean()\n",
    "    data_iq['station_min_temp_c_rolling_avg'] = data_iq['station_min_temp_c'].rolling(window = n).mean()\n",
    "    data_iq['station_precip_mm_rolling_avg'] = data_iq['station_precip_mm'].rolling(window = n).mean()\n",
    "\n",
    "\n",
    "    data_iq['week_start_date'] = pd.to_datetime(data_iq['week_start_date']).dt.month\n",
    "\n",
    "\n",
    "    data_iq.drop(data_iq.head(n).index, inplace=True)\n",
    "\n",
    "    # data_labels_iq_year = data_labels_iq.groupby(['year'])['total_cases'].stdev().to_frame(name = 'annual_cases').reset_index()\n",
    "    # data_labels_iq = pd.merge(data_labels_iq, data_labels_iq_year)\n",
    "    # data_labels_iq['pct_cases_year'] = data_labels_iq['total_cases'] / data_labels_iq['annual_cases']\n",
    "\n",
    "\n",
    "    # Features - Normalize\n",
    "    data_iq_n = MinMaxScaler().fit_transform(data_iq[data_iq.columns[4:43]])\n",
    "    data_iq_n = pd.DataFrame(data_iq_n, columns = data_iq.columns[4:43], index=data_iq.index)\n",
    "    data_iq_n = data_iq_n.drop(columns=['total_cases'])\n",
    "    data_iq_n['month'] = data_iq['month']\n",
    "    data_iq_n['odd_year'] = data_iq['odd_year']\n",
    "\n",
    "\n",
    "    # Features Test\n",
    "    data_iq_lastnweek = data_features[data_features.city=='sj'].reset_index(drop = True).tail(n)\n",
    "    data_test_iq = data_test[data_test.city=='sj'].reset_index(drop = True)\n",
    "    frames = [data_iq_lastnweek, data_test_iq]\n",
    "    data_test_iq = pd.concat(frames).reset_index(drop = True)\n",
    "\n",
    "    data_test_iq = data_test_iq.drop(columns=['reanalysis_sat_precip_amt_mm', 'reanalysis_specific_humidity_g_per_kg'])\n",
    "    data_test_iq = data_test_iq.fillna(method = 'ffill')\n",
    "    data_test_iq['month'] = pd.to_datetime(data_test_iq['week_start_date']).dt.month\n",
    "    data_test_iq['odd_year'] = data_test_iq.year.astype('int64') % 2 == 1\n",
    "    data_test_iq['ndvi_mean'] = (data_test_iq['ndvi_ne'] + data_test_iq['ndvi_nw'] + data_test_iq['ndvi_se'] + data_test_iq['ndvi_sw']) / 4.0\n",
    "\n",
    "    data_test_iq['ndvi_mean_rolling_avg'] = data_test_iq['ndvi_mean'].rolling(window = n).mean()\n",
    "    data_test_iq['ndvi_ne_rolling_avg'] = data_test_iq['ndvi_ne'].rolling(window = n).mean()\n",
    "    data_test_iq['ndvi_nw_rolling_avg'] = data_test_iq['ndvi_nw'].rolling(window = n).mean()\n",
    "    data_test_iq['ndvi_se_rolling_avg'] = data_test_iq['ndvi_se'].rolling(window = n).mean()\n",
    "    data_test_iq['ndvi_sw_rolling_avg'] = data_test_iq['ndvi_sw'].rolling(window = n).mean()\n",
    "    data_test_iq['precipitation_amt_mm_rolling_avg'] = data_test_iq['precipitation_amt_mm'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_air_temp_k_rolling_avg'] = data_test_iq['reanalysis_air_temp_k'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_avg_temp_k_rolling_avg'] = data_test_iq['reanalysis_avg_temp_k'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_dew_point_temp_k_rolling_avg'] = data_test_iq['reanalysis_dew_point_temp_k'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_max_air_temp_k_rolling_avg'] = data_test_iq['reanalysis_max_air_temp_k'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_min_air_temp_k_rolling_avg'] = data_test_iq['reanalysis_min_air_temp_k'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_precip_amt_kg_per_m2_rolling_avg'] = data_test_iq['reanalysis_precip_amt_kg_per_m2'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_relative_humidity_percent_rolling_avg'] = data_test_iq['reanalysis_relative_humidity_percent'].rolling(window = n).mean()\n",
    "    data_test_iq['reanalysis_tdtr_k_rolling_avg'] = data_test_iq['reanalysis_tdtr_k'].rolling(window = n).mean()\n",
    "    data_test_iq['station_avg_temp_c_rolling_avg'] = data_test_iq['station_avg_temp_c'].rolling(window = n).mean()\n",
    "    data_test_iq['station_diur_temp_rng_c_rolling_avg'] = data_test_iq['station_diur_temp_rng_c'].rolling(window = n).mean()\n",
    "    data_test_iq['station_max_temp_c_rolling_avg'] = data_test_iq['station_max_temp_c'].rolling(window = n).mean()\n",
    "    data_test_iq['station_min_temp_c_rolling_avg'] = data_test_iq['station_min_temp_c'].rolling(window = n).mean()\n",
    "    data_test_iq['station_precip_mm_rolling_avg'] = data_test_iq['station_precip_mm'].rolling(window = n).mean()\n",
    "\n",
    "    data_test_iq.drop(data_test_iq.head(n).index, inplace=True)\n",
    "\n",
    "    # Features Test - Normalized\n",
    "    data_test_iq_n = MinMaxScaler().fit_transform(data_test_iq[data_test_iq.columns[4:43]])\n",
    "    data_test_iq_n = pd.DataFrame(data_test_iq_n, columns = data_test_iq.columns[4:43], index=data_test_iq.index)\n",
    "    data_test_iq_n['month'] = data_test_iq['month']\n",
    "    data_test_iq_n['odd_year'] = data_test_iq['odd_year']\n",
    "    \n",
    "    \n",
    "    ###############################################################\n",
    "    # Training Data\n",
    "    ###############################################################\n",
    "\n",
    "    train_features_iq, test_features_iq, train_outcome_iq, test_outcome_iq = train_test_split(\n",
    "        data_iq_n[['month', 'odd_year', 'ndvi_sw_rolling_avg',\n",
    "           'precipitation_amt_mm_rolling_avg',\n",
    "           'reanalysis_dew_point_temp_k_rolling_avg',\n",
    "           'reanalysis_precip_amt_kg_per_m2_rolling_avg',\n",
    "           'reanalysis_relative_humidity_percent_rolling_avg',\n",
    "           'station_diur_temp_rng_c_rolling_avg',\n",
    "           'station_max_temp_c_rolling_avg']],\n",
    "        data_iq['total_cases'],\n",
    "        test_size = 0.3\n",
    "    )\n",
    "    \n",
    "    ###############################################################\n",
    "    # Grid Search\n",
    "    ###############################################################\n",
    "    \n",
    "    params = {'n_neighbors':range(1, 50), 'weights':['uniform', 'distance']}\n",
    "    folds = KFold(n_splits = 10, shuffle=True)\n",
    "    grid_search = GridSearchCV(KNeighborsRegressor(), param_grid=params, cv=folds, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(train_features_iq, train_outcome_iq)\n",
    "    \n",
    "    grid_search.score(test_features_iq, test_outcome_iq)\n",
    "    grid_search.cv_results_['params'][grid_search.best_index_]\n",
    "    \n",
    "    knr_reg = KNeighborsRegressor(n_neighbors = 5, weights = 'distance')\n",
    "    knr_preds_iq = knr_reg.fit(train_features_iq, train_outcome_iq).predict(test_features_iq)\n",
    "    \n",
    "    print(\"done\")\n",
    "    #### ###################################\n",
    "    #Adding to the DataFrame\n",
    "    \n",
    "    error = mean_absolute_error(test_outcome_iq, knr_preds_iq)\n",
    "    print(n)\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
